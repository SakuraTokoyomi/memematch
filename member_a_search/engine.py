import faiss
import numpy as np
import json
import os
import time
from sentence_transformers import SentenceTransformer

try:
    from . import config
except ImportError:
    import config

class SearchEngine:
    # ... (init, _load_resources, _get_ranks functions are all correct and unchanged) ...
    def __init__(self):
        print("âš™ï¸ åˆå§‹åŒ– *ä¸¤è·¯æ··åˆ* æœç´¢å¼•æ“...")
        self.image_model = None
        self.text_model = None
        self.image_index = None
        self.text_index = None
        self.metadata = []
        self.index_size = 0
        self._load_resources()

    def _load_resources(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹ã€ç´¢å¼•å’Œå…ƒæ•°æ®æ–‡ä»¶"""
        try:
            print(f"ğŸ”„ åŠ è½½å›¾åƒæ¨¡å‹: {config.IMAGE_MODEL_NAME}...")
            self.image_model = SentenceTransformer(config.IMAGE_MODEL_NAME)
            print(f"ğŸ”„ åŠ è½½æ–‡æœ¬æ¨¡å‹: {config.TEXT_MODEL_NAME}...")
            self.text_model = SentenceTransformer(config.TEXT_MODEL_NAME)
            
            print(f"ğŸ”„ åŠ è½½å›¾åƒç´¢å¼•: {config.IMAGE_FAISS_INDEX_FILE}...")
            self.image_index = faiss.read_index(config.IMAGE_FAISS_INDEX_FILE)
            print(f"ğŸ”„ åŠ è½½æ–‡æœ¬ç´¢å¼•: {config.TEXT_FAISS_INDEX_FILE}...")
            self.text_index = faiss.read_index(config.TEXT_FAISS_INDEX_FILE)
            
            print(f"ğŸ”„ åŠ è½½å…ƒæ•°æ®: {config.METADATA_FILE}...")
            with open(config.METADATA_FILE, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
            
            self.index_size = len(self.metadata)
            print(f"âœ… æœç´¢å¼•æ“å‡†å¤‡å°±ç»ª (å…± {self.index_size} æ¡æ•°æ®)")
            
        except Exception as e:
            print(f"âŒ åŠ è½½èµ„æºæ—¶å‡ºé”™: {e}")
            self.image_index = None # ç¡®ä¿åœ¨å‡ºé”™æ—¶æœç´¢ä¼šå¤±è´¥

    def _get_ranks(self, search_results):
        indices = search_results[1][0]
        return {id_val: rank for rank, id_val in enumerate(indices) if id_val != -1}

    def search_meme_internal(self, query: str, top_k: int, min_score: float) -> dict:
        
        start_time = time.time() 

        if not self.image_index or not self.text_index:
            raise Exception("FAISS index not found or not loaded") 

        SEARCH_K = max(100, top_k * 10) 
        K_CONST = 60
        # (*** ä½ åœ¨ä½ çš„ä»£ç ä¸­ å°†å…¶æ”¹ä¸ºäº† 0.25, æˆ‘ä¿ç•™è¿™ä¸ªä¿®æ”¹ ***)
        CONTENT_WEIGHT = 0.25 

        # ... (æœç´¢ã€èåˆã€å½’ä¸€åŒ–éƒ¨åˆ† éƒ½æ˜¯æ­£ç¡®çš„ï¼Œä¿æŒä¸å˜) ...
        query_vector_image = self.image_model.encode([query])
        faiss.normalize_L2(query_vector_image)
        D_img, I_img = self.image_index.search(query_vector_image, SEARCH_K)
        query_vector_text = self.text_model.encode([query])
        faiss.normalize_L2(query_vector_text)
        D_txt, I_txt = self.text_index.search(query_vector_text, SEARCH_K)
        image_ranks = self._get_ranks((D_img, I_img))
        text_ranks = self._get_ranks((D_txt, I_txt))
        fused_scores = {}
        all_ids = set(image_ranks.keys()) | set(text_ranks.keys())
        max_image_score_part = (1.0 * (1.0 / (K_CONST + 0)))
        max_content_score_part = (CONTENT_WEIGHT * (1.0 / (K_CONST + 0)))
        fused_normalized_scores = {}
        for id_val in all_ids:
            if id_val >= len(self.metadata): continue
            meta = self.metadata[id_val]
            rrf_score = 0.0
            max_possible_rrf_score = 0.0
            rank = image_ranks.get(id_val)
            if rank is not None:
                rrf_score += 1.0 * (1.0 / (K_CONST + rank))
            max_possible_rrf_score += max_image_score_part
            if meta.get('content'):
                rank = text_ranks.get(id_val)
                if rank is not None:
                    rrf_score += CONTENT_WEIGHT * (1.0 / (K_CONST + rank))
                max_possible_rrf_score += max_content_score_part
            normalized_score = (rrf_score / max_possible_rrf_score) if max_possible_rrf_score > 0 else 0.0
            fused_normalized_scores[id_val] = min(normalized_score, 1.0)
        
        sorted_results = sorted(fused_normalized_scores.items(), key=lambda item: item[1], reverse=True)
        
        # --- (*** æ ¸å¿ƒä¿®æ­£ï¼šåº”ç”¨ä½ çš„æ–°è§„åˆ™ ***) ---
        
        # 1. ä»ç„¶å…ˆæŒ‰ API çš„ min_score è¿‡æ»¤ (é€šå¸¸æ˜¯ 0.0)
        filtered_by_min_score = [(id_val, score) for id_val, score in sorted_results if score >= min_score]
        
        # 2. æ£€æŸ¥ï¼šæ˜¯å¦æ‰¾åˆ°äº†ä»»ä½•ç»“æœï¼Ÿ
        if not filtered_by_min_score:
            raise Exception("Search failed: No results found matching min_score") 

        # 3. æ£€æŸ¥ï¼šTop 1 çš„åˆ†æ•°æ˜¯å¦è¾¾æ ‡ï¼Ÿ (æŒ‰ä½ çš„æ–°è¦æ±‚)
        top_1_score = filtered_by_min_score[0][1]
        SCORE_THRESHOLD = 0.8 #
        
        if top_1_score <= SCORE_THRESHOLD:
            raise Exception(f"Search failed: Top 1 result score ({top_1_score:.4f}) is not > {SCORE_THRESHOLD}")

        # 4. å¦‚æœ Top 1 è¾¾æ ‡ï¼Œåˆ™æœç´¢æˆåŠŸã€‚æˆ‘ä»¬ä»è¿™ä¸ªåˆ—è¡¨ä¸­å– top_k
        final_candidates = filtered_by_min_score[:top_k]
        
        # --- (*** ä¿®æ­£ç»“æŸ ***) ---
        
        results_list = []
        for id_val, normalized_score in final_candidates:
            meta = self.metadata[id_val]
            
            results_list.append({
                "image_path": os.path.join(config.IMAGES_DIR, meta['filename']), 
                "score": round(normalized_score, 4),
                "tags": [meta['emotion']] if meta.get('emotion') else [], 
                "metadata": { 
                    "file_size": meta.get('file_size', 0),
                    "dimensions": meta.get('dimensions', [0,0]),
                    "format": meta.get('format', 'unknown')
                }
            })
        
        return {
            "success": True,
            "data": {
                "query": query,
                "results": results_list,
                "total": len(results_list),
                # (*** ä¿®æ­£ 'filtered' çš„è®¡ç®—é€»è¾‘ ***)
                "filtered": len(filtered_by_min_score) - len(final_candidates)
            },
            "metadata": {
                "search_time": time.time() - start_time,
                "index_size": self.index_size,
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S")
            }
        }

# --- (å¯¹å¤–æš´éœ²çš„æ¥å£ä¸å˜) ---
_engine_instance = None
def get_search_engine():
    global _engine_instance
    if _engine_instance is None:
        _engine_instance = SearchEngine()
    return _engine_instance

def search_meme(query: str, top_k: int = 5, min_score: float = 0.0) -> dict: 
    engine = get_search_engine()
    
    try:
        return engine.search_meme_internal(
            query=query, 
            top_k=top_k, 
            min_score=min_score
        )
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "error_code": "SEARCH_ERROR"
        }