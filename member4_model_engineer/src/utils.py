"""
å·¥å…·å‡½æ•°æ¨¡å—
æä¾›æ•°æ®åŠ è½½ã€æŒ‡æ ‡è®¡ç®—ã€ç»“æœä¿å­˜ç­‰é€šç”¨åŠŸèƒ½
"""

import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any
import yaml


def load_config(config_path: str = "config/models.yaml") -> Dict:
    """
    åŠ è½½é…ç½®æ–‡ä»¶
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        é…ç½®å­—å…¸
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def load_meme_data(meme_path: str) -> Tuple[List[str], List[str], List[str]]:
    """
    åŠ è½½è¡¨æƒ…åŒ…æ•°æ®
    
    Args:
        meme_path: è¡¨æƒ…åŒ…JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        (meme_ids, meme_texts, meme_labels)
    """
    with open(meme_path, 'r', encoding='utf-8') as f:
        memes = json.load(f)
    
    meme_ids = []
    meme_texts = []
    meme_labels = []
    
    for meme in memes:
        meme_ids.append(meme['id'])
        meme_labels.append(meme['label'])
        
        # ç»„åˆæ ‡ç­¾å’Œå…³é”®è¯ä½œä¸ºæè¿°æ–‡æœ¬
        keywords = ' '.join(meme.get('keywords', []))
        description = meme.get('description', '')
        text = f"{meme['label']} {keywords} {description}".strip()
        meme_texts.append(text)
    
    return meme_ids, meme_texts, meme_labels


def load_query_data(query_path: str, split: str = 'test') -> Tuple[List[str], List[str]]:
    """
    åŠ è½½æŸ¥è¯¢æ•°æ®
    
    Args:
        query_path: æŸ¥è¯¢JSONæ–‡ä»¶è·¯å¾„
        split: 'train' æˆ– 'test'
        
    Returns:
        (query_ids, query_texts)
    """
    with open(query_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    queries = data.get(split, [])
    query_ids = [q['id'] for q in queries]
    query_texts = [q['text'] for q in queries]
    
    return query_ids, query_texts


def load_ground_truth(query_path: str, split: str = 'test') -> Dict[str, List[str]]:
    """
    åŠ è½½æ ‡æ³¨ç­”æ¡ˆ
    
    Args:
        query_path: åŒ…å«ground_truthçš„JSONæ–‡ä»¶è·¯å¾„
        split: 'train' æˆ– 'test'
        
    Returns:
        {query_id: [meme_ids]}
    """
    with open(query_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    ground_truth = data.get('ground_truth', {}).get(split, {})
    return ground_truth


def compute_recall_at_k(predictions: np.ndarray, 
                        ground_truth: Dict[str, List[str]], 
                        query_ids: List[str],
                        meme_ids: List[str],
                        k: int) -> float:
    """
    è®¡ç®— Recall@k
    
    Args:
        predictions: ç›¸ä¼¼åº¦çŸ©é˜µ (n_queries, n_memes)
        ground_truth: æ ‡æ³¨ç­”æ¡ˆå­—å…¸
        query_ids: æŸ¥è¯¢IDåˆ—è¡¨
        meme_ids: è¡¨æƒ…åŒ…IDåˆ—è¡¨
        k: Top-k
        
    Returns:
        recall@k åˆ†æ•°
    """
    recalls = []
    
    for query_idx, query_id in enumerate(query_ids):
        # è·å–æ ‡æ³¨çš„æ­£ç¡®ç­”æ¡ˆ
        relevant_memes = ground_truth.get(query_id, [])
        if not relevant_memes:
            continue
        
        # è·å–Top-ké¢„æµ‹
        top_k_indices = np.argsort(predictions[query_idx])[-k:][::-1]
        top_k_meme_ids = [meme_ids[i] for i in top_k_indices]
        
        # è®¡ç®—å‘½ä¸­æ•°
        hits = len(set(top_k_meme_ids) & set(relevant_memes))
        recall = hits / len(relevant_memes)
        recalls.append(recall)
    
    return np.mean(recalls) if recalls else 0.0


def compute_mrr(predictions: np.ndarray,
                ground_truth: Dict[str, List[str]],
                query_ids: List[str],
                meme_ids: List[str]) -> float:
    """
    è®¡ç®— Mean Reciprocal Rank (MRR)
    
    Args:
        predictions: ç›¸ä¼¼åº¦çŸ©é˜µ
        ground_truth: æ ‡æ³¨ç­”æ¡ˆå­—å…¸
        query_ids: æŸ¥è¯¢IDåˆ—è¡¨
        meme_ids: è¡¨æƒ…åŒ…IDåˆ—è¡¨
        
    Returns:
        MRR åˆ†æ•°
    """
    mrrs = []
    
    for query_idx, query_id in enumerate(query_ids):
        relevant_memes = ground_truth.get(query_id, [])
        if not relevant_memes:
            continue
        
        # è·å–æ’åºåçš„é¢„æµ‹
        ranked_indices = np.argsort(predictions[query_idx])[::-1]
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç›¸å…³ç»“æœçš„ä½ç½®
        for rank, idx in enumerate(ranked_indices, 1):
            if meme_ids[idx] in relevant_memes:
                mrrs.append(1.0 / rank)
                break
    
    return np.mean(mrrs) if mrrs else 0.0


def compute_metrics(predictions: np.ndarray,
                    ground_truth: Dict[str, List[str]],
                    query_ids: List[str],
                    meme_ids: List[str]) -> Dict[str, float]:
    """
    è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡
    
    Returns:
        åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
    """
    metrics = {
        'recall@1': compute_recall_at_k(predictions, ground_truth, query_ids, meme_ids, k=1),
        'recall@3': compute_recall_at_k(predictions, ground_truth, query_ids, meme_ids, k=3),
        'recall@5': compute_recall_at_k(predictions, ground_truth, query_ids, meme_ids, k=5),
        'mrr': compute_mrr(predictions, ground_truth, query_ids, meme_ids)
    }
    
    return metrics


def save_results(results: List[Dict[str, Any]], output_path: str):
    """
    ä¿å­˜è¯„ä¼°ç»“æœä¸ºCSV
    
    Args:
        results: ç»“æœåˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    df = pd.DataFrame(results)
    df.to_csv(output_path, index=False, encoding='utf-8')
    print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {output_path}")


def load_data(data_dir: str = "data", 
              meme_file: str = "memes.json",
              query_file: str = "queries_sample.json",
              split: str = "test") -> Tuple:
    """
    ä¸€ç«™å¼æ•°æ®åŠ è½½å‡½æ•°
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        meme_file: è¡¨æƒ…åŒ…æ–‡ä»¶å
        query_file: æŸ¥è¯¢æ–‡ä»¶å
        split: æ•°æ®é›†åˆ’åˆ†
        
    Returns:
        (meme_ids, meme_texts, query_ids, query_texts, ground_truth)
    """
    data_path = Path(data_dir)
    
    # åŠ è½½è¡¨æƒ…åŒ…
    meme_ids, meme_texts, _ = load_meme_data(str(data_path / meme_file))
    
    # åŠ è½½æŸ¥è¯¢
    query_ids, query_texts = load_query_data(str(data_path / query_file), split)
    
    # åŠ è½½æ ‡æ³¨
    ground_truth = load_ground_truth(str(data_path / query_file), split)
    
    print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   - è¡¨æƒ…åŒ…æ•°é‡: {len(meme_ids)}")
    print(f"   - æŸ¥è¯¢æ•°é‡: {len(query_ids)} ({split} set)")
    print(f"   - æ ‡æ³¨å¯¹æ•°: {len(ground_truth)}")
    
    return meme_ids, meme_texts, query_ids, query_texts, ground_truth


def format_report(model_name: str, metrics: Dict[str, float], inference_time: float = None) -> str:
    """
    æ ¼å¼åŒ–è¯„ä¼°æŠ¥å‘Š
    
    Args:
        model_name: æ¨¡å‹åç§°
        metrics: æŒ‡æ ‡å­—å…¸
        inference_time: æ¨ç†æ—¶é—´ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    report = f"\n{'='*60}\n"
    report += f"æ¨¡å‹: {model_name}\n"
    report += f"{'='*60}\n"
    report += f"Recall@1: {metrics['recall@1']:.4f}\n"
    report += f"Recall@3: {metrics['recall@3']:.4f}\n"
    report += f"Recall@5: {metrics['recall@5']:.4f}\n"
    report += f"MRR:      {metrics['mrr']:.4f}\n"
    
    if inference_time:
        report += f"æ¨ç†æ—¶é—´: {inference_time:.3f}s\n"
    
    report += f"{'='*60}\n"
    
    return report


