"""
å‘é‡å¯¼å‡ºå™¨
è´Ÿè´£å°†è¡¨æƒ…åŒ…æè¿°ç¼–ç ä¸ºå‘é‡å¹¶å¯¼å‡ºï¼Œä¾›æ£€ç´¢ç³»ç»Ÿï¼ˆæˆå‘˜3ï¼‰ä½¿ç”¨
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict
from sentence_transformers import SentenceTransformer


class EmbeddingExporter:
    """
    å‘é‡å¯¼å‡ºå™¨
    
    åŠŸèƒ½ï¼š
    1. åŠ è½½æœ€ä½³æ¨¡å‹
    2. æ‰¹é‡ç¼–ç è¡¨æƒ…åŒ…æè¿°
    3. å¯¼å‡ºå‘é‡æ–‡ä»¶ï¼ˆ.npyæ ¼å¼ï¼‰
    4. å¯¼å‡ºå…ƒæ•°æ®ï¼ˆIDæ˜ å°„ã€æ–‡æœ¬ç­‰ï¼‰
    """
    
    def __init__(self, model_name_or_path: str):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨
        
        Args:
            model_name_or_path: æ¨¡å‹åç§°æˆ–è·¯å¾„
        """
        self.model_name = model_name_or_path
        print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_name_or_path}")
        self.model = SentenceTransformer(model_name_or_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
    
    def export_meme_embeddings(self,
                              meme_data_path: str,
                              output_dir: str,
                              batch_size: int = 32):
        """
        å¯¼å‡ºè¡¨æƒ…åŒ…å‘é‡
        
        Args:
            meme_data_path: è¡¨æƒ…åŒ…JSONæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        print(f"\nğŸ“¦ å¼€å§‹å¯¼å‡ºå‘é‡...")
        print(f"   è¾“å…¥: {meme_data_path}")
        print(f"   è¾“å‡º: {output_dir}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # 1. åŠ è½½è¡¨æƒ…åŒ…æ•°æ®
        print("ğŸ“– åŠ è½½è¡¨æƒ…åŒ…æ•°æ®...")
        with open(meme_data_path, 'r', encoding='utf-8') as f:
            memes = json.load(f)
        
        # 2. æ„å»ºæè¿°æ–‡æœ¬
        meme_ids = []
        meme_texts = []
        meme_labels = []
        
        for meme in memes:
            meme_ids.append(meme['id'])
            meme_labels.append(meme['label'])
            
            # ç»„åˆï¼šæ ‡ç­¾ + å…³é”®è¯ + æè¿°
            keywords = ' '.join(meme.get('keywords', []))
            description = meme.get('description', '')
            text = f"{meme['label']} {keywords} {description}".strip()
            meme_texts.append(text)
        
        print(f"   è¡¨æƒ…åŒ…æ•°é‡: {len(meme_ids)}")
        
        # 3. ç¼–ç å‘é‡
        print("ğŸ”¢ ç¼–ç å‘é‡...")
        embeddings = self.model.encode(
            meme_texts,
            batch_size=batch_size,
            show_progress_bar=True,
            convert_to_numpy=True
        )
        
        print(f"   å‘é‡å½¢çŠ¶: {embeddings.shape}")
        print(f"   å‘é‡ç»´åº¦: {embeddings.shape[1]}")
        
        # 4. ä¿å­˜å‘é‡æ–‡ä»¶
        embeddings_file = output_path / "meme_embeddings.npy"
        np.save(embeddings_file, embeddings.astype(np.float32))
        print(f"âœ… å‘é‡å·²ä¿å­˜: {embeddings_file}")
        
        # 5. ä¿å­˜IDæ˜ å°„
        ids_file = output_path / "meme_ids.json"
        with open(ids_file, 'w', encoding='utf-8') as f:
            json.dump(meme_ids, f, ensure_ascii=False, indent=2)
        print(f"âœ… IDæ˜ å°„å·²ä¿å­˜: {ids_file}")
        
        # 6. ä¿å­˜æ–‡æœ¬åˆ—è¡¨ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
        texts_file = output_path / "meme_texts.txt"
        with open(texts_file, 'w', encoding='utf-8') as f:
            for meme_id, label, text in zip(meme_ids, meme_labels, meme_texts):
                f.write(f"{meme_id}\t{label}\t{text}\n")
        print(f"âœ… æ–‡æœ¬åˆ—è¡¨å·²ä¿å­˜: {texts_file}")
        
        # 7. ä¿å­˜å…ƒæ•°æ®
        metadata = {
            "model_name": self.model_name,
            "num_memes": len(meme_ids),
            "embedding_dimension": int(embeddings.shape[1]),
            "dtype": "float32",
            "files": {
                "embeddings": "meme_embeddings.npy",
                "ids": "meme_ids.json",
                "texts": "meme_texts.txt"
            },
            "usage": {
                "python": {
                    "load_embeddings": "embeddings = np.load('meme_embeddings.npy')",
                    "load_ids": "ids = json.load(open('meme_ids.json'))"
                },
                "description": "ä¾›æˆå‘˜3ï¼ˆæ£€ç´¢ç³»ç»Ÿå·¥ç¨‹å¸ˆï¼‰ä½¿ç”¨"
            }
        }
        
        metadata_file = output_path / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {metadata_file}")
        
        # 8. è¾“å‡ºä½¿ç”¨è¯´æ˜
        print(f"\n{'='*60}")
        print(f"âœ… å‘é‡å¯¼å‡ºå®Œæˆ!")
        print(f"{'='*60}")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   - {embeddings_file.name}  (å‘é‡æ•°æ®)")
        print(f"   - {ids_file.name}  (IDæ˜ å°„)")
        print(f"   - {texts_file.name}  (æ–‡æœ¬åˆ—è¡¨)")
        print(f"   - {metadata_file.name}  (å…ƒæ•°æ®)")
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼ˆä¾›æˆå‘˜3ï¼‰:")
        print(f"   import numpy as np")
        print(f"   import json")
        print(f"   embeddings = np.load('{embeddings_file}')")
        print(f"   with open('{ids_file}') as f:")
        print(f"       meme_ids = json.load(f)")
        print(f"{'='*60}\n")
        
        return embeddings, meme_ids, meme_texts
    
    def export_query_embeddings(self,
                               query_texts: List[str],
                               query_ids: List[str],
                               output_file: str):
        """
        å¯¼å‡ºæŸ¥è¯¢å‘é‡ï¼ˆå¯é€‰ï¼Œç”¨äºç¼“å­˜ï¼‰
        
        Args:
            query_texts: æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨
            query_ids: æŸ¥è¯¢IDåˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“ ç¼–ç æŸ¥è¯¢å‘é‡...")
        embeddings = self.model.encode(
            query_texts,
            show_progress_bar=True,
            convert_to_numpy=True
        )
        
        # ä¿å­˜
        np.save(output_file, embeddings.astype(np.float32))
        
        # ä¿å­˜IDæ˜ å°„
        ids_file = output_file.replace('.npy', '_ids.json')
        with open(ids_file, 'w', encoding='utf-8') as f:
            json.dump(query_ids, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æŸ¥è¯¢å‘é‡å·²ä¿å­˜: {output_file}")
        return embeddings

