"""
æ¨¡å‹è¯„ä¼°å™¨
è´Ÿè´£åŠ è½½å¥å‘é‡æ¨¡å‹ã€ç¼–ç æ–‡æœ¬ã€è®¡ç®—ç›¸ä¼¼åº¦ã€è¯„ä¼°æ€§èƒ½
"""

import numpy as np
import time
from typing import List, Dict, Tuple
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

from .utils import compute_metrics


class MemeModelEvaluator:
    """
    è¡¨æƒ…åŒ…åŒ¹é…æ¨¡å‹è¯„ä¼°å™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åŠ è½½é¢„è®­ç»ƒå¥å‘é‡æ¨¡å‹
    2. ç¼–ç æ–‡æœ¬ä¸ºå‘é‡
    3. è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
    4. è¯„ä¼°æ£€ç´¢æ€§èƒ½ï¼ˆRecall@k, MRRï¼‰
    """
    
    def __init__(self, model_name: str, device: str = None):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            model_name: HuggingFaceæ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„
            device: 'cpu', 'cuda', 'mps' æˆ– Noneï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
        """
        self.model_name = model_name
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
        
        try:
            self.model = SentenceTransformer(model_name, device=device)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print(f"   è®¾å¤‡: {self.model.device}")
            print(f"   å‘é‡ç»´åº¦: {self.model.get_sentence_embedding_dimension()}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def encode_texts(self, texts: List[str], batch_size: int = 32, 
                     show_progress: bool = True) -> np.ndarray:
        """
        ç¼–ç æ–‡æœ¬ä¸ºå‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            å‘é‡çŸ©é˜µ (n_texts, embedding_dim)
        """
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=show_progress,
            convert_to_numpy=True
        )
        return embeddings
    
    def compute_similarity(self, query_embeddings: np.ndarray, 
                          meme_embeddings: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—æŸ¥è¯¢ä¸è¡¨æƒ…åŒ…ä¹‹é—´çš„ç›¸ä¼¼åº¦
        
        Args:
            query_embeddings: æŸ¥è¯¢å‘é‡ (n_queries, dim)
            meme_embeddings: è¡¨æƒ…åŒ…å‘é‡ (n_memes, dim)
            
        Returns:
            ç›¸ä¼¼åº¦çŸ©é˜µ (n_queries, n_memes)
        """
        similarities = cosine_similarity(query_embeddings, meme_embeddings)
        return similarities
    
    def evaluate(self, 
                 query_texts: List[str],
                 meme_texts: List[str],
                 ground_truth: Dict[str, List[str]],
                 query_ids: List[str],
                 meme_ids: List[str]) -> Tuple[Dict[str, float], np.ndarray, np.ndarray, float]:
        """
        å®Œæ•´è¯„ä¼°æµç¨‹
        
        Args:
            query_texts: æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨
            meme_texts: è¡¨æƒ…åŒ…æè¿°æ–‡æœ¬åˆ—è¡¨
            ground_truth: æ ‡æ³¨ç­”æ¡ˆ {query_id: [meme_ids]}
            query_ids: æŸ¥è¯¢IDåˆ—è¡¨
            meme_ids: è¡¨æƒ…åŒ…IDåˆ—è¡¨
            
        Returns:
            (metrics, query_embeddings, meme_embeddings, inference_time)
        """
        print(f"\nğŸ”¬ å¼€å§‹è¯„ä¼°æ¨¡å‹: {self.model_name}")
        print(f"   æŸ¥è¯¢æ•°é‡: {len(query_texts)}")
        print(f"   è¡¨æƒ…åŒ…æ•°é‡: {len(meme_texts)}")
        
        # 1. ç¼–ç è¡¨æƒ…åŒ…ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
        print("ğŸ“ ç¼–ç è¡¨æƒ…åŒ…æè¿°...")
        start_time = time.time()
        meme_embeddings = self.encode_texts(meme_texts, show_progress=False)
        meme_time = time.time() - start_time
        
        # 2. ç¼–ç æŸ¥è¯¢
        print("ğŸ“ ç¼–ç æŸ¥è¯¢å¥å­...")
        start_time = time.time()
        query_embeddings = self.encode_texts(query_texts, show_progress=False)
        query_time = time.time() - start_time
        
        total_time = meme_time + query_time
        print(f"â±ï¸  ç¼–ç è€—æ—¶: {total_time:.3f}s")
        print(f"   - è¡¨æƒ…åŒ…: {meme_time:.3f}s ({len(meme_texts)/meme_time:.1f} å¥/ç§’)")
        print(f"   - æŸ¥è¯¢: {query_time:.3f}s ({len(query_texts)/query_time:.1f} å¥/ç§’)")
        
        # 3. è®¡ç®—ç›¸ä¼¼åº¦
        print("ğŸ”¢ è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ...")
        similarities = self.compute_similarity(query_embeddings, meme_embeddings)
        
        # 4. è®¡ç®—æŒ‡æ ‡
        print("ğŸ“Š è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
        metrics = compute_metrics(similarities, ground_truth, query_ids, meme_ids)
        
        return metrics, query_embeddings, meme_embeddings, total_time
    
    def get_top_k_predictions(self,
                             query_text: str,
                             meme_texts: List[str],
                             meme_ids: List[str],
                             k: int = 3) -> List[Tuple[str, float]]:
        """
        è·å–å•ä¸ªæŸ¥è¯¢çš„Top-ké¢„æµ‹
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            meme_texts: è¡¨æƒ…åŒ…æè¿°åˆ—è¡¨
            meme_ids: è¡¨æƒ…åŒ…IDåˆ—è¡¨
            k: è¿”å›Top-kä¸ªç»“æœ
            
        Returns:
            [(meme_id, similarity_score), ...]
        """
        # ç¼–ç 
        query_emb = self.encode_texts([query_text], show_progress=False)[0]
        meme_embs = self.encode_texts(meme_texts, show_progress=False)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity([query_emb], meme_embs)[0]
        
        # è·å–Top-k
        top_k_indices = np.argsort(similarities)[-k:][::-1]
        results = [(meme_ids[i], similarities[i]) for i in top_k_indices]
        
        return results
    
    def get_embedding_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        return self.model.get_sentence_embedding_dimension()
    
    def save_model(self, output_path: str):
        """
        ä¿å­˜æ¨¡å‹ï¼ˆå¦‚æœæ˜¯å¾®è°ƒåçš„æ¨¡å‹ï¼‰
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„
        """
        self.model.save(output_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜è‡³: {output_path}")


